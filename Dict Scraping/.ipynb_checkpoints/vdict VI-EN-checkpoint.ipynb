{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pb5cLSUaNY3G"
   },
   "outputs": [],
   "source": [
    "import urllib.request \n",
    "from urllib.parse import quote \n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 109330,
     "status": "ok",
     "timestamp": 1591976076647,
     "user": {
      "displayName": "Duc Trinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3DueJ-17c3iJPH_c7OMUo_rfEVfRvjkQWSrqG=s64",
      "userId": "03125855697250476054"
     },
     "user_tz": -420
    },
    "id": "wuFb6KEAOGnq",
    "outputId": "59fcb299-143e-42df-f034-171b4c51423f"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7PByvekNY3K"
   },
   "outputs": [],
   "source": [
    "#Source: https://codezup.com/web-scraping-word-meaning-dictionary-python-beautifulsoup/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Mfzh6pjNY3N"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./bigFreqList.json') as json_file:\n",
    "     wordsData = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Ks4W-vJs39f"
   },
   "outputs": [],
   "source": [
    "#generate a list of words with frequency higher than the threshold\n",
    "def generateWordList(threshold): \n",
    "  temp = []\n",
    "  for (word, freq) in wordsData.items():\n",
    "    if (freq >= threshold):\n",
    "      temp.append(word)\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116632,
     "status": "ok",
     "timestamp": 1591976084028,
     "user": {
      "displayName": "Duc Trinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3DueJ-17c3iJPH_c7OMUo_rfEVfRvjkQWSrqG=s64",
      "userId": "03125855697250476054"
     },
     "user_tz": -420
    },
    "id": "kNKJsHh_s5B4",
    "outputId": "904b7b6e-d6eb-4263-f3a3-05cfe9a683f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['latikivn', 'imusicvn', 'ycđt', 'greatland', 'lemmevn', 'hoclamgiau', 'hpschoolvn', 'khochiasevn', 'hakiba', 'heisvn']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "141836"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordList = generateWordList(40)\n",
    "print(wordList[-10:])\n",
    "len(wordList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T0e9gQ4ps6qq"
   },
   "outputs": [],
   "source": [
    "#break the word list into batches of \n",
    "batches = [wordList[i:i + 10000] for i in range(0, len(wordList), 10000)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 116608,
     "status": "ok",
     "timestamp": 1591976084038,
     "user": {
      "displayName": "Duc Trinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3DueJ-17c3iJPH_c7OMUo_rfEVfRvjkQWSrqG=s64",
      "userId": "03125855697250476054"
     },
     "user_tz": -420
    },
    "id": "lV5nJ_BctBuL",
    "outputId": "21d7aeb0-57c7-4b0f-c852-bab946bf5a30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "1836\n"
     ]
    }
   ],
   "source": [
    "for batch in batches:\n",
    "  print(len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vN8pA-6SNY3Q"
   },
   "outputs": [],
   "source": [
    "#The link format for vdict Viet-Eng is: https://vdict.com/m%E1%BB%99t,2,0,0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12XqYQC2NY3S"
   },
   "outputs": [],
   "source": [
    "#Converting IRI to ASCII:\n",
    "#https://stackoverflow.com/questions/4389572/how-to-fetch-a-non-ascii-url-with-python-urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l68WK1qhNY3U"
   },
   "outputs": [],
   "source": [
    "def findTranslation(word):\n",
    "    print(\"Finding translation for \" + word)\n",
    "    url = \"https://vdict.com/\" + quote(word) + \",2,0,0.html\" #resolving the IRI issue\n",
    "    \n",
    "    try: #make sure the link is working\n",
    "        source = urllib.request.urlopen(url)\n",
    "    except:\n",
    "        print(\"Link broken for \" + word)\n",
    "        return \"N/A\"\n",
    "    \n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "    #make sure the word is in the dictionary\n",
    "    if (soup.find(\"div\", id = 'result-contents') is None):\n",
    "        print(\"Not in the dictionary \" + word)\n",
    "        return \"N/A\"\n",
    "    \n",
    "    translations = {}\n",
    "\n",
    "    #Getting the first POS tag\n",
    "    firstPosTag = soup.find(\"div\", class_ = 'phanloai')\n",
    "    \n",
    "    if (firstPosTag is None): #empty translation page\n",
    "        print(\"Empty translation page \" + word)\n",
    "        return \"N/A\"\n",
    "    \n",
    "    curPos = firstPosTag.string.split(' \\xa0')[0]\n",
    "\n",
    "    #first translation is a tag away from the first POS tag\n",
    "    curTag = firstPosTag.next_sibling.next_sibling\n",
    "\n",
    "    #storing the number of translations a word has\n",
    "    numTrans = 1\n",
    "\n",
    "    #continue while we are either in a POS tag or a translation tag\n",
    "    while (curTag != '\\n'): \n",
    "        if (curTag.attrs[\"class\"] == [\"list1\"]): #a translation\n",
    "            temp = {} #temp dict to store each translation of a word\n",
    "\n",
    "            #getting the raw translation\n",
    "            if (curTag.find('b').string is not None): #empty translation cell\n",
    "                temp['translation'] = re.split('[,;]', curTag.find('b').string)\n",
    "                temp['POS'] = curPos\n",
    "\n",
    "                #retrieving the examples of each of the translations\n",
    "                try:\n",
    "                    examples = curTag.findAll(\"ul\", class_= \"list2\")\n",
    "                    temp2 = {} #another dict to store each examples of a translation\n",
    "\n",
    "                    numExamples = len(list(examples))\n",
    "                    temp2['nums'] = numExamples\n",
    "\n",
    "                    for j in range(0, numExamples):\n",
    "                        temp2['context ' + str(j+1)] = examples[j].find(class_ = \"example-original\").string\n",
    "\n",
    "                        #retrieving the usage of each examples\n",
    "                        try: \n",
    "                            tempString = str(examples[j].find(\"li\")) #extracting the usage\n",
    "                            temp2['usage ' + str(j+1)] = str(examples[j].find(\"li\").contents[-1])\n",
    "                        except:\n",
    "                            temp2['usage ' + str(j+1)] = \"N/A\"\n",
    "\n",
    "                    temp['examples'] = temp2\n",
    "                except:\n",
    "                    temp['examples'] = \"N/A\"\n",
    "\n",
    "                translations[numTrans] = temp #adding the translation to the dictionary\n",
    "\n",
    "                numTrans += 1\n",
    "            curTag = curTag.next_sibling                \n",
    "        else: #a tag\n",
    "            curPos = curTag.string.split(' \\xa0')[0]\n",
    "            curTag = curTag.next_sibling\n",
    "\n",
    "    #storing the number of translations\n",
    "    translations['nums'] = numTrans - 1\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCBUgS80NY3X"
   },
   "outputs": [],
   "source": [
    "url = \"https://vdict.com/\" + quote(\"có\") + \",2,0,0.html\" #resolving the IRI issue\n",
    "\n",
    "try:\n",
    "    source = urllib.request.urlopen(url)\n",
    "except:\n",
    "    print( \"Link broken\")\n",
    "soup = BeautifulSoup(source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 117281,
     "status": "ok",
     "timestamp": 1591976084772,
     "user": {
      "displayName": "Duc Trinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3DueJ-17c3iJPH_c7OMUo_rfEVfRvjkQWSrqG=s64",
      "userId": "03125855697250476054"
     },
     "user_tz": -420
    },
    "id": "sj3-cZn8NY3Z",
    "outputId": "8e690dc4-3181-49dc-8eb7-f839b865ed98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"div\", class_ = 'phanloai').next_sibling.next_sibling.next_sibling.next_sibling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4709962,
     "status": "error",
     "timestamp": 1591813981095,
     "user": {
      "displayName": "Duc Trinh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh3DueJ-17c3iJPH_c7OMUo_rfEVfRvjkQWSrqG=s64",
      "userId": "03125855697250476054"
     },
     "user_tz": -420
    },
    "id": "-zI2ezLJNY3d",
    "outputId": "819186d9-c1be-420b-873a-17aa95928637"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8299608d28da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "#from google.colab import files\n",
    "start_time = time.time()\n",
    "\n",
    "index = 3\n",
    "batch = batches[index] + batches[index+1]\n",
    "\n",
    "#for (index, batch) in enumerate(batches):\n",
    "dictionary = {}\n",
    "\n",
    "#making the dictionary for each batch\n",
    "for word in batch:\n",
    "    dictionary[word] = findTranslation(word)\n",
    "    time.sleep(1) #wait for 1 sec between each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ba85NhIj1sa"
   },
   "outputs": [],
   "source": [
    "dictionary = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HfoCJDOvxOJ"
   },
   "outputs": [],
   "source": [
    "#saving the batch\n",
    "with open('./vdict VI-EN batch {}.json'.format(\"34\"), 'w') as outfile:\n",
    "  json.dump(dictionary, outfile)\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BGzXuUvQNY3k"
   },
   "outputs": [],
   "source": [
    "findTranslation(\"cái\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "vdict VI-EN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#got from https://medium.com/the-artificial-impostor/detecting-chinese-characters-in-unicode-strings-4ac839ba313a\n",
    "#detect whether there is Han character in word\n",
    "def detectCJK(word):\n",
    "    if re.search(\"[\\u4e00-\\u9FFF]\", word):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find whether the word is in the list\n",
    "def containsWord(word, lst):\n",
    "    return word.lower() in [elem.lower() for elem in lst]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find whether the same word, translation pair is in the other dict\n",
    "def hasTranslation(word, translation,  dct):\n",
    "    #remove weird square brackets from wikt2dict\n",
    "    translation = translation.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "\n",
    "    #ignoring Chinese characters\n",
    "    if detectCJK(translation): #detect whether there are any Chinese characters in there\n",
    "        return False\n",
    "\n",
    "    #the translation is also in the other dict for the word\n",
    "    elif(containsWord(translation, dct[word])):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Triangulate Paths/wikt hu-fr-vi.json', './Triangulate Paths/vdict hu-fr-vi.json', './Triangulate Paths/soha hu-en-vi.json', './Triangulate Paths/wikt hu-en-vi.json', './Triangulate Paths/soha hu-fr-vi.json', './Triangulate Paths/vdict hu-en-vi.json']\n",
      "{'./Triangulate Paths/wikt hu-fr-vi.json': 0, './Triangulate Paths/vdict hu-fr-vi.json': 1, './Triangulate Paths/soha hu-en-vi.json': 2, './Triangulate Paths/wikt hu-en-vi.json': 3, './Triangulate Paths/soha hu-fr-vi.json': 4, './Triangulate Paths/vdict hu-en-vi.json': 5}\n"
     ]
    }
   ],
   "source": [
    "dictFiles = glob.glob(\"./Triangulate Paths/*\")\n",
    "print(dictFiles)\n",
    "pathsDict = {file:index for (index, file) in enumerate(dictFiles)}\n",
    "print(pathsDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intial dict is wikt hu-fr-vi.json\n",
      "Outputting in ./Confirmed by Paths/confirmed wikt hu-fr-vi\n",
      "Word -izmus is translated to chủ nghĩa, and it occurs in [0, 2, 3, 5], with a confidence score of 0.6666666666666666\n",
      "Word DNS is translated to DNA, and it occurs in [0, 3], with a confidence score of 0.3333333333333333\n",
      "Word dezoxiribonukleinsav is translated to DNA, and it occurs in [0, 3], with a confidence score of 0.3333333333333333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-8cc65bb8c6c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0motherFiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     \u001b[0motherDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0motherDict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasTranslation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranslation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motherDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(0, 1):\n",
    "    #use one source as the initial dictionary\n",
    "    initialFile = dictFiles[i]\n",
    "    otherFiles = dictFiles[:i] + dictFiles[i+1:]\n",
    "    \n",
    "    with open(initialFile, \"r\") as infile:\n",
    "        initialDict = json.load(infile)\n",
    "    \n",
    "    initialName = initialFile.split(\"/\")[-1]\n",
    "    print(\"The intial dict is {}\".format(initialName))\n",
    "    \n",
    "    outputPath = \"./Confirmed by Paths/\" + \"confirmed \" + initialName.split(\".\")[0]\n",
    "    print(\"Outputting in {}\".format(outputPath))\n",
    "    outfile = open(outputPath, \"w\")\n",
    "    for (word, translations) in initialDict.items():\n",
    "        for translation in translations:\n",
    "            occurCount = 1\n",
    "            occurIn = [pathsDict[initialFile]]\n",
    "            #checking if any of the translation exist in another dict\n",
    "            for file in otherFiles:\n",
    "                with open(file, \"r\") as infile:\n",
    "                    otherDict = json.load(infile)\n",
    "\n",
    "                if (word in otherDict and hasTranslation(word, translation, otherDict)):\n",
    "                    occurCount += 1\n",
    "                    occurIn.append(pathsDict[file])\n",
    "                    \n",
    "            if occurCount > 1:\n",
    "                conf = occurCount/6\n",
    "                outfile.write(word + \"\\t\" + translation + \"\\t\" + translation + \"\\t\" + str(occurIn) +\n",
    "                             str(conf))\n",
    "                print(\"Word {} is translated to {}, and it occurs in {}, with a confidence score of {}\"\n",
    "                      .format(word, translation, occurIn, conf))\n",
    "    outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
